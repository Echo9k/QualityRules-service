{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "path_root = Path.cwd()\n",
    "while not (path_root / \"data\").exists():\n",
    "    if path_root == path_root.parent:\n",
    "        raise FileNotFoundError(\"Directory 'data' not found\")\n",
    "    path_root = path_root.parent\n",
    "\n",
    "path_data = path_root / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Backend Service**: FastAPI\n",
    "\n",
    "We'll use FastAPI to serve your model and provide an endpoint for querying.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. **Set up FastAPI**.\n",
    "2. **Load your existing FAISS index and embeddings**.\n",
    "3. **Serve a POST endpoint** to handle user queries and return the most similar rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Query\n",
    "from pydantic import BaseModel\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize FastAPI\n",
    "app = FastAPI(title=\"Rule Search Service\", description=\"A local API to search for the most adequate rules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_path = path_root / \"data\"\n",
    "model_path = path_root / \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path / \"tokenizer\")\n",
    "model = AutoModel.from_pretrained(model_path / \"model\")\n",
    "\n",
    "# Load rule definitions and FAISS index\n",
    "df_defs = pd.read_json(data_path / 'internim/definitions.json')[['RuleID', 'Description']]\n",
    "index = faiss.read_index(str(data_path / \"processed/faiss_index.idx\"))  # Prebuilt index file\n",
    "\n",
    "# Function to generate embeddings\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Search function\n",
    "def search_faiss(query: str, top_k: int = 5):\n",
    "    query_embedding = get_embeddings(query).reshape(1, -1)\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    results = df_defs.iloc[indices[0]]\n",
    "    return results, distances[0]\n",
    "\n",
    "# API Input Schema\n",
    "class QueryInput(BaseModel):\n",
    "    query: str\n",
    "    top_k: int = 5\n",
    "\n",
    "# Endpoint for querying\n",
    "@app.post(\"/search/\")\n",
    "def search_rules(input: QueryInput):\n",
    "    results, distances = search_faiss(input.query, input.top_k)\n",
    "    response = []\n",
    "    for i, row in results.iterrows():\n",
    "        response.append({\n",
    "            \"RuleID\": row[\"RuleID\"],\n",
    "            \"Description\": row[\"Description\"],\n",
    "            \"Distance\": float(distances[i])\n",
    "        })\n",
    "    return {\"results\": response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
